{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3ce511",
   "metadata": {},
   "source": [
    "# Texas Heat-Related Mortality Estimates\n",
    "This notebook accompanies the manuscript **\"The True Cost of Heat: Evaluating Heat-Related Mortality Estimation Methods in Texas\"**. It calculates heat-related deaths across Texas counties using the optimal temperature method, extreme heat method, and excess death method, based on ERA5 reanalysis data and mortality statistics.\n",
    "\n",
    "**Code Author:** Jesse R. J. Rutt  \n",
    "**For Questions about the code contact:** jesse_rutt@tamu.edu  \n",
    "**Last Updated:** June 2025  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "016d4404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries are available and imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install missing packages and import libraries\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "required_packages = {\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"xarray\": \"xarray\",\n",
    "    \"netCDF4\": \"netCDF4\",  # for full xarray NetCDF support\n",
    "    \"json\": None  # built-in, no install needed\n",
    "}\n",
    "\n",
    "for module, package in required_packages.items():\n",
    "    try:\n",
    "        importlib.import_module(module)\n",
    "    except ImportError:\n",
    "        if package:\n",
    "            print(f\"Installing missing package: {package}\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        else:\n",
    "            print(f\"Module '{module}' is built-in and should be available.\")\n",
    "\n",
    "# Re-import after potential install\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import json\n",
    "\n",
    "print(\"All libraries are available and imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22511a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required input files exist.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# === Define base path ===\n",
    "BASE_PATH = Path('/Users/jessesmac/Myprojects/data/coiled_output/')\n",
    "# BASE_PATH = Path('')\n",
    "\n",
    "# === Define all file paths ===\n",
    "paths = {\n",
    "    \"County metadata (JSON)\": BASE_PATH / 'combined_county_data.json',\n",
    "    \"ERA5 temperature data (NetCDF)\": BASE_PATH / 'ERA5/griddedTXmeanTemp.nc',\n",
    "    \"Mortality file (CSV)\": BASE_PATH / 'totals-by-day-texas.csv',\n",
    "    \"OTM reference (84th percentile)\": BASE_PATH / 'ot_smt_mmt_deaths_84th.csv',\n",
    "    \"XHM reference (95th percentile)\": BASE_PATH / 'ot_smt_mmt_deaths_95th.csv',\n",
    "    \"Output file path\": BASE_PATH / 'HRD_CalculationsTable_1985-2006_OT_SMT.csv'\n",
    "}\n",
    "\n",
    "# === Validate paths ===\n",
    "missing_files = [desc for desc, path in paths.items() if not path.exists() and 'Output' not in desc]\n",
    "\n",
    "if missing_files:\n",
    "    raise FileNotFoundError(f\"The following required input files are missing:\\n\" +\n",
    "                            \"\\n\".join(f\"- {desc}\" for desc in missing_files))\n",
    "else:\n",
    "    print(\"All required input files exist.\")\n",
    "\n",
    "# Assign to variables for later use\n",
    "county_data_path = paths[\"County metadata (JSON)\"]\n",
    "temperature_file = paths[\"ERA5 temperature data (NetCDF)\"]\n",
    "mortality_file = paths[\"Mortality file (CSV)\"]\n",
    "ot_84th_path = paths[\"OTM reference (84th percentile)\"]\n",
    "ot_95th_path = paths[\"XHM reference (95th percentile)\"]\n",
    "output_csv_path = paths[\"Output file path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f304d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All file paths are valid.\n"
     ]
    }
   ],
   "source": [
    "# Define input and output paths\n",
    "BASE_PATH = '/Users/jessesmac/Myprojects/data/coiled_output/'\n",
    "\n",
    "county_data_path = BASE_PATH + 'combined_county_data.json'\n",
    "temperature_file = BASE_PATH + 'ERA5/griddedTXmeanTemp.nc'\n",
    "mortality_file = BASE_PATH + 'totals-by-day-texas.csv'\n",
    "ot_84th_path = BASE_PATH + 'ot_smt_mmt_deaths_84th.csv'\n",
    "ot_95th_path = BASE_PATH + 'ot_smt_mmt_deaths_95th.csv'\n",
    "output_csv_path = BASE_PATH + 'HRD_CalculationsTable_1985-2006_OT_SMT.csv'\n",
    "\n",
    "print(\"All file paths are valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b9a21",
   "metadata": {},
   "source": [
    "# Heat-Related Mortality Estimates in Texas By County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78101f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 254 counties.\n"
     ]
    }
   ],
   "source": [
    "# Load all input datasets\n",
    "with open(county_data_path) as f:\n",
    "    county_data = json.load(f)\n",
    "\n",
    "ot_84th_df = pd.read_csv(ot_84th_path)\n",
    "ot_95th_df = pd.read_csv(ot_95th_path)\n",
    "population_data = pd.read_csv(mortality_file).groupby('county')['population'].mean().to_dict()\n",
    "\n",
    "print(f\"Loaded {len(county_data)} counties.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "459c1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ot_smt_mmt(county, df):\n",
    "    \"\"\"\n",
    "    Retrieve OT, SMT, and baseline MMT deaths for a given county.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        row = df[df['county'] == county]\n",
    "        return row['OT'].values[0], row['SMT'].values[0], row['mmt_deaths'].values[0]\n",
    "    except IndexError:\n",
    "        return None, None, 0\n",
    "\n",
    "def calculate_hrd(county, start_year, end_year, lat, lon, baseline_df):\n",
    "    \"\"\"\n",
    "    Estimate total heat-related deaths from daily temperature time series.\n",
    "    \"\"\"\n",
    "    dataset = xr.open_dataset(temperature_file).squeeze()\n",
    "    total_hrd = 0\n",
    "    ot, smt, mmt_deaths = get_ot_smt_mmt(county, baseline_df)\n",
    "    if ot is None:\n",
    "        return 0\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        temps = dataset.sel(lat=lat, lon=lon, method='nearest').sel(time=slice(f'{year}-01-01', f'{year}-12-31')).to_dataframe()\n",
    "        temps['t2m'] -= 273.15  # Kelvin to Celsius\n",
    "\n",
    "        rr_func = lambda t: 1 - 0.0014 * (smt - 30.9) * (t - ot) ** 2 + 0.005 * (smt - 26.7) * (t - ot)\n",
    "        temps['rr'] = rr_func(temps['t2m'])\n",
    "        temps['heatDeaths'] = (temps['rr'] - 1) * mmt_deaths\n",
    "        temps.loc[temps['t2m'] < ot, 'heatDeaths'] = 0\n",
    "\n",
    "        total_hrd += temps['heatDeaths'].sum()\n",
    "\n",
    "    return total_hrd\n",
    "\n",
    "def calculate_excess_hrd(county, lat, lon, df):\n",
    "    return calculate_hrd(county, 2010, 2023, lat, lon, df) - calculate_hrd(county, 1950, 1963, lat, lon, df)\n",
    "\n",
    "def format_population(pop):\n",
    "    return round(pop / 1000, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f01507f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'County': [],\n",
    "    'Population (Thousands)': [],\n",
    "    'OTM HRD': [],\n",
    "    'XHM HRD': [],\n",
    "    'Excess OTM': [],\n",
    "    'Excess XHM': []\n",
    "}\n",
    "\n",
    "for county, info in county_data.items():\n",
    "    lat, lon = info['latitude'], info['longitude']\n",
    "    population = population_data.get(county.upper(), 0)\n",
    "    if population == 0:\n",
    "        continue\n",
    "\n",
    "    otm = calculate_hrd(county, 2010, 2023, lat, lon, ot_84th_df)\n",
    "    xhm = calculate_hrd(county, 2010, 2023, lat, lon, ot_95th_df)\n",
    "    excess_otm = calculate_excess_hrd(county, lat, lon, ot_84th_df)\n",
    "    excess_xhm = calculate_excess_hrd(county, lat, lon, ot_95th_df)\n",
    "\n",
    "    results['County'].append(county)\n",
    "    results['Population (Thousands)'].append(format_population(population))\n",
    "    results['OTM HRD'].append(round(otm, 1))\n",
    "    results['XHM HRD'].append(round(xhm, 1))\n",
    "    results['Excess OTM'].append(round(excess_otm, 1))\n",
    "    results['Excess XHM'].append(round(excess_xhm, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b099c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Counties by Population and HRD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Population (Thousands)</th>\n",
       "      <th>OTM HRD</th>\n",
       "      <th>XHM HRD</th>\n",
       "      <th>Excess OTM</th>\n",
       "      <th>Excess XHM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARRIS</td>\n",
       "      <td>4629.4</td>\n",
       "      <td>1584.3</td>\n",
       "      <td>400.7</td>\n",
       "      <td>1000.8</td>\n",
       "      <td>322.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DALLAS</td>\n",
       "      <td>2583.9</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>464.4</td>\n",
       "      <td>918.3</td>\n",
       "      <td>351.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TARRANT</td>\n",
       "      <td>2050.9</td>\n",
       "      <td>1629.8</td>\n",
       "      <td>401.3</td>\n",
       "      <td>787.1</td>\n",
       "      <td>294.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEXAR</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>953.5</td>\n",
       "      <td>183.5</td>\n",
       "      <td>557.8</td>\n",
       "      <td>138.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>1234.2</td>\n",
       "      <td>512.1</td>\n",
       "      <td>90.6</td>\n",
       "      <td>306.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COLLIN</td>\n",
       "      <td>996.0</td>\n",
       "      <td>559.5</td>\n",
       "      <td>144.0</td>\n",
       "      <td>281.6</td>\n",
       "      <td>105.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HIDALGO</td>\n",
       "      <td>856.5</td>\n",
       "      <td>203.9</td>\n",
       "      <td>43.7</td>\n",
       "      <td>151.3</td>\n",
       "      <td>41.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DENTON</td>\n",
       "      <td>848.7</td>\n",
       "      <td>411.2</td>\n",
       "      <td>104.7</td>\n",
       "      <td>194.7</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ELPASO</td>\n",
       "      <td>844.6</td>\n",
       "      <td>560.9</td>\n",
       "      <td>72.7</td>\n",
       "      <td>339.1</td>\n",
       "      <td>52.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>FORTBEND</td>\n",
       "      <td>774.1</td>\n",
       "      <td>167.6</td>\n",
       "      <td>39.5</td>\n",
       "      <td>109.9</td>\n",
       "      <td>33.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      County  Population (Thousands)  OTM HRD  XHM HRD  Excess OTM  Excess XHM\n",
       "1     HARRIS                  4629.4   1584.3    400.7      1000.8       322.8\n",
       "2     DALLAS                  2583.9   1768.0    464.4       918.3       351.2\n",
       "3    TARRANT                  2050.9   1629.8    401.3       787.1       294.7\n",
       "0      BEXAR                  1955.0    953.5    183.5       557.8       138.8\n",
       "4     TRAVIS                  1234.2    512.1     90.6       306.0        73.0\n",
       "5     COLLIN                   996.0    559.5    144.0       281.6       105.6\n",
       "7    HIDALGO                   856.5    203.9     43.7       151.3        41.7\n",
       "6     DENTON                   848.7    411.2    104.7       194.7        74.9\n",
       "59    ELPASO                   844.6    560.9     72.7       339.1        52.7\n",
       "64  FORTBEND                   774.1    167.6     39.5       109.9        33.6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(by='Population (Thousands)', ascending=False)\n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"Top 10 Counties by Population and HRD:\")\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b572faf",
   "metadata": {},
   "source": [
    "# Heat-Related Mortality Estimates in Texas By Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4460c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compact per-year HRD and excess HRD calculations using existing functions/data\n",
    "def calculate_total_hrd_by_year(year, df):\n",
    "    total = 0\n",
    "    for county, loc in county_data.items():\n",
    "        lat, lon = loc['latitude'], loc['longitude']\n",
    "        ot, smt, mmt = get_ot_smt_mmt(county, df)\n",
    "        if ot is None:\n",
    "            continue\n",
    "        temps = xr.open_dataset(temperature_file).squeeze().sel(lat=lat, lon=lon, method='nearest')\n",
    "        temps = temps.sel(time=slice(f'{year}-01-01', f'{year}-12-31')).to_dataframe()\n",
    "        temps['t2m'] -= 273.15\n",
    "        rr = lambda t: 1 - 0.0014 * (smt - 30.9) * (t - ot)**2 + 0.005 * (smt - 26.7) * (t - ot)\n",
    "        temps['rr'] = rr(temps['t2m'])\n",
    "        temps['heatDeaths'] = (temps['rr'] - 1) * mmt\n",
    "        temps.loc[temps['t2m'] < ot, 'heatDeaths'] = 0\n",
    "        total += temps['heatDeaths'].sum()\n",
    "    return total\n",
    "\n",
    "def calculate_excess_by_year(year, df):\n",
    "    return calculate_total_hrd_by_year(year, df) - calculate_total_hrd_by_year(1950 + (year - 2010), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93244dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined official death counts\n",
    "official_deaths = {\n",
    "    2010: 115, 2011: 218, 2012: 99, 2013: 88, 2014: 82, 2015: 85,\n",
    "    2016: 141, 2017: 85, 2018: 137, 2019: 159, 2020: 141, 2021: 241,\n",
    "    2022: 419, 2023: 563\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86a3d52e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ss/4zp4zlc10qqbg74ddmjhz64c0000gn/T/ipykernel_18553/1421715046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Save results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdf_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_by_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0myear_csv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'HRD_CalculationsTable_ByYear_2010-2023.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdf_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# Compile yearly results\n",
    "results_by_year = {\n",
    "    \"Year\": [], \"OTM HRD\": [], \"XHM HRD\": [],\n",
    "    \"Excess OTM\": [], \"Excess XHM\": [], \"Official Deaths\": []\n",
    "}\n",
    "\n",
    "for year in range(2010, 2024):\n",
    "    otm = calculate_total_hrd_by_year(year, ot_84th_df)\n",
    "    xhm = calculate_total_hrd_by_year(year, ot_95th_df)\n",
    "    results_by_year[\"Year\"].append(year)\n",
    "    results_by_year[\"OTM HRD\"].append(round(otm, 1))\n",
    "    results_by_year[\"XHM HRD\"].append(round(xhm, 1))\n",
    "    results_by_year[\"Excess OTM\"].append(round(calculate_excess_by_year(year, ot_84th_df), 1))\n",
    "    results_by_year[\"Excess XHM\"].append(round(calculate_excess_by_year(year, ot_95th_df), 1))\n",
    "    results_by_year[\"Official Deaths\"].append(official_deaths[year])\n",
    "\n",
    "# Save results\n",
    "df_year = pd.DataFrame(results_by_year)\n",
    "year_csv_path = BASE_PATH / 'HRD_CalculationsTable_ByYear_2010-2023.csv'\n",
    "df_year.to_csv(year_csv_path, index=False)\n",
    "\n",
    "print(f\"Yearly HRD summary saved to: {year_csv_path}\")\n",
    "df_year.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
